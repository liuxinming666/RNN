{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "文本处理",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epBP8eFkZ9Ys",
        "colab_type": "text"
      },
      "source": [
        "# 文本处理测试"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHFsJtX2W9tG",
        "colab_type": "text"
      },
      "source": [
        "解压缩文件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op_c09WaW71W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "import zipfile\n",
        "\n",
        "filePath = '/content/drive/My Drive/Colab Notebooks/深度学习/wed/04-第四课 卷积神经网络/04-第四课第四周编程作业.zip'\n",
        "outPath = '/content/drive/My Drive/Colab Notebooks/深度学习/wed/04-第四课 卷积神经网络'\n",
        "z = zipfile.ZipFile(filePath, 'r')\n",
        "z.extractall(path=outPath)\n",
        "z.close()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTMCmO3wkJbQ",
        "colab_type": "text"
      },
      "source": [
        "安装结巴分词器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYIPAbW_jvCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install jieba"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t88n1OBxkUfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import jieba\n",
        "\n",
        "#seg_list = jieba.cut(\"我家在河南省郑州市\", cut_all=False)\n",
        "#print(\"Default Mode: \" + \"/\".join(seg_list))  # 精确模式"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGrHgX3C0MXe",
        "colab_type": "text"
      },
      "source": [
        "读取数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWbq3yNd0L2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "with open(\"/content/drive/My Drive/数据集/商品描述文案数据集/item_desc_dataset.txt\", \"r\") as f:\n",
        "  data = f.readline()\n",
        "  seg_list = jieba.cut(data, cut_all=False)\n",
        "  #print(data)\n",
        "  print(\"/\".join(seg_list))\n",
        "'''\n",
        "\n",
        "'''\n",
        "f = open(\"/content/drive/My Drive/数据集/商品描述文案数据集/item_desc_dataset.txt\", \"r\")\n",
        "maxLen = 0\n",
        "dataLen = 0\n",
        "while True:\n",
        "  line = f.readline()\n",
        "  sAry = line.split('\\t',1)\n",
        "  seg_list = jieba.cut(sAry[1], cut_all=False)\n",
        "  #print(sAry[1])\n",
        "  #print(\"/\".join(seg_list))\n",
        "  #print(len(list(seg_list)))\n",
        "  maxLen = max(maxLen,len(list(seg_list)))\n",
        "  dataLen = dataLen + 1\n",
        "  print(maxLen)\n",
        "  if not line:\n",
        "    break\n",
        "print('记录条数为:',dataLen)\n",
        "print('句子最长为:',maxLen)\n",
        "f.close()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUGg6DjFjXJM",
        "colab_type": "text"
      },
      "source": [
        "读取预训练词向量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aNqwprc-0aO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "ilePath = '/content/drive/My Drive/Colab Notebooks/RNN/预训练词向量/sgns.target.word-word.dynwin5.thr10.neg5.dim300.iter5'\n",
        "f = open(filePath, \"r\")\n",
        "while True:\n",
        "  line = f.readline()\n",
        "  print(line)\n",
        "  if not line:\n",
        "    break\n",
        "'''    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kbG7FgEbNWe",
        "colab_type": "text"
      },
      "source": [
        "# 导入类库"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixEYSqsnbRYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import time\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "\n",
        "try:\n",
        "  # Use the %tensorflow_version magic if in colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO_EnxJOaI38",
        "colab_type": "text"
      },
      "source": [
        "# 古诗数据处理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m92GcmzeaO_8",
        "colab_type": "text"
      },
      "source": [
        "读取古诗,将古诗存在数组中"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90QlBUTTaUgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "poetry_file = '/content/drive/My Drive/数据集/古诗文本/poetry.txt'\n",
        "# 诗集  \n",
        "poetrys = []\n",
        "filterSAry = [\"_\", \"(\", \"《\",\"[\"]\n",
        "index = 0  \n",
        "with open(poetry_file, \"r\") as f:  \n",
        "    for line in f: \n",
        "      line = line.strip('\\n')\n",
        "      lineAry = line.strip(' ').split(':')\n",
        "      title = lineAry[0]\n",
        "      content = lineAry[1]\n",
        "\n",
        "      if '_' in content or '（' in content or '《' in content or '[' in content:\n",
        "        continue\n",
        "      if len(content) < 5 or len(content) > 79:\n",
        "        continue\n",
        "      \n",
        "      content = content + ']'\n",
        "      poetrys.append(content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX9m0_TnVGMH",
        "colab_type": "text"
      },
      "source": [
        "按诗的字数排序"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeeSG01iVNNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "poetrys = sorted(poetrys,key=lambda poetry:len(poetry))\n",
        "print('诗的总数为:',len(poetrys))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0KEn_e7HJ4r",
        "colab_type": "text"
      },
      "source": [
        "统计每首诗的长度,并统计相同长度的诗都各有多少首，统计出哪种长度的诗个数最多"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyn25TsCG7EU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "poetrys_length = [len(poetry) for poetry in poetrys]\n",
        "counter = collections.Counter(poetrys_length)\n",
        "poetrys_length,poetrys_num = zip(*counter.items())\n",
        "#求出最多个数的索引\n",
        "poertyLength_maxNum_index = np.argmax(poetrys_num)\n",
        "#print(counter)\n",
        "print('数量最多的诗的长度为:',poetrys_length[poertyLength_maxNum_index])\n",
        "print('数量最多的诗的个数为:',poetrys_num[poertyLength_maxNum_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsjTqMWxSK3j",
        "colab_type": "text"
      },
      "source": [
        "将个数最多的诗装进列表"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LUAgZjOSKM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "poetrys_train = [poetry for poetry in poetrys if len(poetry) == 49]\n",
        "print('将要参与训练的诗的个数为:',len(poetrys_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uWVXLyDYhF7",
        "colab_type": "text"
      },
      "source": [
        "统计每个字出现的次数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ2CsofaYlaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 统计每个字出现次数\n",
        "start = time.clock()\n",
        "all_words = []\n",
        "for poetry in poetrys_train:\n",
        "  all_words += [word for word in poetry]\n",
        "#words = list(set(all_words))\n",
        "words_count = collections.Counter(all_words)\n",
        "words_count = sorted(\n",
        "    words_count.items(), \n",
        "    key=lambda x: x[1],\n",
        "    reverse=True)\n",
        "words,_ = zip(*words_count)\n",
        "end = time.clock()\n",
        "print('一共有',len(words),'个字符')\n",
        "print('用时:',end - start)\n",
        "print(words[:10])\n",
        "#print(list(set(result)).sort(key=result.))    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAjpQvq9Vesk",
        "colab_type": "text"
      },
      "source": [
        "# 构造训练数据集"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9GWC5jHWKhI",
        "colab_type": "text"
      },
      "source": [
        "定义初始变量，文本的长度为49,参与训练的样本为12530个"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YR_Jn2TVkJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_num = 12530\n",
        "maxlen = 49"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpaD5bcjhzO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#将字符映射为数组，并将数字映射为字符\n",
        "char_to_ix = {ch:i+1 for i,ch in enumerate(words)}\n",
        "ix_to_char = {i+1:ch for i,ch in enumerate(words)}\n",
        "\n",
        "'''\n",
        "print(ix_to_char)\n",
        "print(ix_to_char[4])\n",
        "print(char_to_ix)\n",
        "print(char_to_ix['不'])\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jucm5k4ntv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "import random\n",
        "print(poetrys_train[0])\n",
        "random.shuffle(poetrys_train)\n",
        "print(poetrys_train[0])\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeWzts5-Wlbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#构造一个生成器\n",
        "#x shape为 (batch,maxlen - 1,len(words)+1)\n",
        "#y shape为 (batch,maxlen - 1,len(words)+1)\n",
        "def gen_generator():\n",
        "  dataLength = len(poetrys_train)\n",
        "  batch = 32\n",
        "  while True:\n",
        "    random.shuffle(poetrys_train)\n",
        "    data_batch = np.zeros((32, maxlen))\n",
        "    for i in range(dataLength):\n",
        "      for wix,word in enumerate(poetrys_train[i]):\n",
        "        data_batch[i%batch,wix] = char_to_ix[word]\n",
        "      if (i%(batch-1)) == 0 and i != 0:\n",
        "        data_baatch_oneHot = tf.keras.utils.to_categorical(data_batch,num_classes=len(words) + 1)\n",
        "        x = data_baatch_oneHot[:,:maxlen - 1,:]\n",
        "        y = data_baatch_oneHot[:,1:,:]\n",
        "        yield (x,y)\n",
        "\n",
        "'''\n",
        "gen = gen_generator()\n",
        "A = next(gen)\n",
        "print(A[0].shape)\n",
        "print(A[1].shape)\n",
        "print(A[2].shape)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-26t8np0pSH",
        "colab_type": "text"
      },
      "source": [
        "# 构造模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQxJPK3zPvyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#构造模型\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(\n",
        "    1024,\n",
        "    return_sequences = True,\n",
        "    input_shape=(maxlen - 1,len(words)+1)))\n",
        "#model.add(tf.keras.layers.LSTM(128,return_sequences = True))\n",
        "model.add(tf.keras.layers.Dense(len(words) + 1,activation='softmax'))\n",
        "#model.add(tf.keras.layers.LSTM(len(words) + 1))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su_G2I7jW_f_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIXjv_zN07ML",
        "colab_type": "text"
      },
      "source": [
        "# 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lIn6G0MRyeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#训练模型\n",
        "gen = gen_generator()\n",
        "train_epochs = 100\n",
        "stepsPerEpochs = math.floor(len(poetrys_train)/32)\n",
        "model.fit_generator(gen,\n",
        "          epochs=train_epochs,\n",
        "          steps_per_epoch=stepsPerEpochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQXhtduI1EL3",
        "colab_type": "text"
      },
      "source": [
        "# 保存模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMAos7N2ecPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#模型保存\n",
        "modelPath = '/content/drive/My Drive/myModel/rnn-poetrys-100.h5'\n",
        "model.save(modelPath)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXoGfLpQ1IyV",
        "colab_type": "text"
      },
      "source": [
        "# 加载训练好的模型进行测试"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqH-ggQJ1Mqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#加载模型\n",
        "modelPath = '/content/drive/My Drive/myModel/rnn-poetrys-100.h5'\n",
        "model = tf.keras.models.load_model(modelPath)\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvnee8H91rR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#计算出第一个字是什么\n",
        "#x shape为 (batch,maxlen - 1,len(words)+1)\n",
        "#y shape为 (batch,maxlen - 1,len(words)+1)\n",
        "x = np.zeros(shape=(1,maxlen - 1,len(words) + 1))\n",
        "y = model.predict(x)\n",
        "firstWord_oneHot = y[0,0,:]\n",
        "print(firstWord_oneHot.shape)\n",
        "idx = np.argmax(firstWord_oneHot,axis=-1)\n",
        "firstWord = ix_to_char[idx]\n",
        "print(firstWord)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAv54O0PpsnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(maxlen - 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2wTLjIHofO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#循环的出每一个字\n",
        "genPoetry = []\n",
        "genPoetry.append(firstWord)\n",
        "xPoetry = np.zeros(shape=(1,maxlen - 1,len(words) + 1))\n",
        "xPoetry[0,0] = firstWord_oneHot\n",
        "#print(np.argmax(xPoetry[0,0]))\n",
        "for i in range(maxlen - 2):\n",
        "  y = model.predict(xPoetry)\n",
        "  if i < (maxlen -1):\n",
        "    xPoetry[0,i+1] = y[0,i,:]\n",
        "  idxTmp = np.argmax(y[0,i,:],axis=-1)\n",
        "  genPoetry.append(ix_to_char[idxTmp])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKBvCH8qsFcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"生成的诗为：\")\n",
        "print(\"\".join(genPoetry))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMlwuPZmUcY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T = np.random.randint(low=0,high=2,size=(5,6))\n",
        "print(T)\n",
        "print(T[:,:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOCN-ny3326g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(poetrys_train[0])\n",
        "print(char_to_ix['随'])\n",
        "#print(ix_to_char[508])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gwayggdpiaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = np.random.randint(low=0,high=10,size=(8,6,5))\n",
        "B = tf.keras.utils.to_categorical(A,num_classes=10)\n",
        "print(A)\n",
        "print(A[0])\n",
        "print(B,B.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FM4DYHWtYq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 取前多少个常用字\n",
        "words = words[:len(words)] + (' ',)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7xlKzaIuJ5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 每个字映射为一个数字ID\n",
        "word_num_map = dict(zip(words,range(len(words))))\n",
        "print(word_num_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbV6TFFzvhH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 把诗转换为向量形式，参考TensorFlow练习1\n",
        "to_num = lambda word: word_num_map.get(word, len(words))\n",
        "poetrys_vector = [ list(map(to_num, poetry)) for poetry in poetrys]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}